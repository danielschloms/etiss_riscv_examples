def @main(%input_1: Tensor[(1, 640), int8], %v_param_1: Tensor[(128, 640), int8], %v_param_2: Tensor[(128), int32], %v_param_3: Tensor[(128, 128), int8], %v_param_4: Tensor[(128), int32], %v_param_5: Tensor[(128, 128), int8], %v_param_6: Tensor[(128), int32], %v_param_7: Tensor[(128, 128), int8], %v_param_8: Tensor[(128), int32], %v_param_9: Tensor[(8, 128), int8], %v_param_10: Tensor[(8), int32], %v_param_11: Tensor[(128, 8), int8], %v_param_12: Tensor[(128), int32], %v_param_13: Tensor[(128, 128), int8], %v_param_14: Tensor[(128), int32], %v_param_15: Tensor[(128, 128), int8], %v_param_16: Tensor[(128), int32], %v_param_17: Tensor[(128, 128), int8], %v_param_18: Tensor[(128), int32], %v_param_19: Tensor[(640, 128), int8], %v_param_20: Tensor[(640), int32], output_tensor_names=["Identity"]) {
  %0 = reshape(%input_1, newshape=[-1, 640]);
  %1 = qnn.dense(%0, %v_param_1, 89, 0, 0.391015f, 0.000376875f, units=128, out_dtype="int32");
  %2 = nn.bias_add(%1, %v_param_2);
  %3 = qnn.requantize(%2, 0.000147364f, 0, 0.0494591f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %4 = clip(%3, a_min=-128f, a_max=127f);
  %5 = reshape(%4, newshape=[-1, 128]);
  %6 = qnn.dense(%5, %v_param_3, -128, 0, 0.0494591f, 0.0150283f, units=128, out_dtype="int32");
  %7 = nn.bias_add(%6, %v_param_4);
  %8 = qnn.requantize(%7, 0.000743288f, 0, 0.0354057f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %9 = clip(%8, a_min=-128f, a_max=127f);
  %10 = reshape(%9, newshape=[-1, 128]);
  %11 = qnn.dense(%10, %v_param_5, -128, 0, 0.0354057f, 0.0535004f, units=128, out_dtype="int32");
  %12 = nn.bias_add(%11, %v_param_6);
  %13 = qnn.requantize(%12, 0.00189422f, 0, 0.0137307f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %14 = clip(%13, a_min=-128f, a_max=127f);
  %15 = reshape(%14, newshape=[-1, 128]);
  %16 = qnn.dense(%15, %v_param_7, -128, 0, 0.0137307f, 0.0720354f, units=128, out_dtype="int32");
  %17 = nn.bias_add(%16, %v_param_8);
  %18 = qnn.requantize(%17, 0.0009891f, 0, 0.0236038f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %19 = clip(%18, a_min=-128f, a_max=127f);
  %20 = reshape(%19, newshape=[-1, 128]);
  %21 = qnn.dense(%20, %v_param_9, -128, 0, 0.0236038f, 0.00834463f, units=8, out_dtype="int32");
  %22 = nn.bias_add(%21, %v_param_10);
  %23 = qnn.requantize(%22, 0.000196965f, 0, 0.0249295f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %24 = clip(%23, a_min=-128f, a_max=127f);
  %25 = reshape(%24, newshape=[-1, 8]);
  %26 = qnn.dense(%25, %v_param_11, -128, 0, 0.0249295f, 0.0267345f, units=128, out_dtype="int32");
  %27 = nn.bias_add(%26, %v_param_12);
  %28 = qnn.requantize(%27, 0.000666477f, 0, 0.0317562f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %29 = clip(%28, a_min=-128f, a_max=127f);
  %30 = reshape(%29, newshape=[-1, 128]);
  %31 = qnn.dense(%30, %v_param_13, -128, 0, 0.0317562f, 0.0193354f, units=128, out_dtype="int32");
  %32 = nn.bias_add(%31, %v_param_14);
  %33 = qnn.requantize(%32, 0.000614019f, 0, 0.0320712f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %34 = clip(%33, a_min=-128f, a_max=127f);
  %35 = reshape(%34, newshape=[-1, 128]);
  %36 = qnn.dense(%35, %v_param_15, -128, 0, 0.0320712f, 0.0128027f, units=128, out_dtype="int32");
  %37 = nn.bias_add(%36, %v_param_16);
  %38 = qnn.requantize(%37, 0.000410599f, 0, 0.028296f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %39 = clip(%38, a_min=-128f, a_max=127f);
  %40 = reshape(%39, newshape=[-1, 128]);
  %41 = qnn.dense(%40, %v_param_17, -128, 0, 0.028296f, 0.00704988f, units=128, out_dtype="int32");
  %42 = nn.bias_add(%41, %v_param_18);
  %43 = qnn.requantize(%42, 0.000199483f, 0, 0.0247909f, -128, rounding="UPWARD", compute_dtype="int64", out_dtype="int8");
  %44 = clip(%43, a_min=-128f, a_max=127f);
  %45 = reshape(%44, newshape=[-1, 128]);
  %46 = qnn.dense(%45, %v_param_19, -128, 0, 0.0247909f, 0.0195567f, units=640, out_dtype="int32");
  %47 = nn.bias_add(%46, %v_param_20);
  qnn.requantize(%47, 0.000484828f, 0, 0.364498f, 96, rounding="UPWARD", compute_dtype="int64", out_dtype="int8")
}
